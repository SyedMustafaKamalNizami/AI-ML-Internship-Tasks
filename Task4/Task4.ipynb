{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1244d8a71abb4052b5de2cc873174f65": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_162d75c6b6974355977e784395ee9ce1",
              "IPY_MODEL_914a58dd43a0436180603de5afb40460",
              "IPY_MODEL_7ffafcca340c4d37bc52d16e6c1221e8"
            ],
            "layout": "IPY_MODEL_c0e3eca472e84dfbb704103eedfa893f"
          }
        },
        "162d75c6b6974355977e784395ee9ce1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7259ebc70719455596705af411eeb111",
            "placeholder": "​",
            "style": "IPY_MODEL_ae134e394be34aedac347f254339a19a",
            "value": "Map: 100%"
          }
        },
        "914a58dd43a0436180603de5afb40460": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c56a9e6087784e319ac196aea52c0b3f",
            "max": 12000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b4bcdc52f07940459d382b28e106f856",
            "value": 12000
          }
        },
        "7ffafcca340c4d37bc52d16e6c1221e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0747bfbe2550404398d0e6e219c8d3ff",
            "placeholder": "​",
            "style": "IPY_MODEL_a113b38b9389494796fc9cccea68cccb",
            "value": " 12000/12000 [00:02&lt;00:00, 4923.66 examples/s]"
          }
        },
        "c0e3eca472e84dfbb704103eedfa893f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7259ebc70719455596705af411eeb111": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ae134e394be34aedac347f254339a19a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c56a9e6087784e319ac196aea52c0b3f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b4bcdc52f07940459d382b28e106f856": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0747bfbe2550404398d0e6e219c8d3ff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a113b38b9389494796fc9cccea68cccb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Task 4:\n",
        "# News Topic Classifier\n",
        "# Objective\n",
        "\n",
        "The objective of this task was to build a text classification system that categorizes news headlines into one of four categories (World, Sports, Business, Sci/Tech). This was achieved by fine-tuning a pretrained BERT model (bert-base-uncased) on the AG News dataset, allowing the model to learn context-specific patterns in news language for accurate classification.\n",
        "\n",
        "# Introduction\n",
        "\n",
        "This task involved applying transfer learning with the BERT model, a widely used transformer-based architecture for natural language processing. The AG News dataset, containing 120,000 training and 7,600 testing samples across four balanced categories, was used. The main goal was to demonstrate how a large pretrained model can be fine-tuned for a specific task without training from scratch. The process included tokenizing the text using the BERT tokenizer, preparing the dataset for training, fine-tuning the classification head, and finally deploying the model for real-time interaction using Gradio.\n",
        "\n",
        "# Overview\n",
        "\n",
        "The workflow began with loading the AG News dataset from Hugging Face Datasets and splitting the training set into training and validation subsets. The bert-base-uncased tokenizer converted each news headline into token IDs and attention masks suitable for BERT input. The model was fine-tuned using Hugging Face’s Trainer API.\n",
        "\n",
        "Evaluation was performed using accuracy and F1-score (weighted) to measure classification performance across all categories. The fine-tuned model and tokenizer were saved locally, and a Hugging Face pipeline was created for easy inference.\n",
        "\n",
        "For deployment, a Gradio interface was implemented, allowing users to input custom headlines and instantly view the predicted category with scores.\n",
        "\n",
        "# Summary\n",
        "\n",
        "This task successfully delivered a fine-tuned BERT-based text classifier capable of categorizing news headlines into predefined topics with strong accuracy and F1 performance. It demonstrated key skills in natural language processing, including tokenization, transformer fine-tuning, and evaluation. Furthermore, lightweight deployment through Gradio showcased how machine learning models can be made interactive and user-friendly."
      ],
      "metadata": {
        "id": "mY4PfpFIxTKC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required packages\n",
        "!pip install -q torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
        "!pip install -q transformers==4.21.0 datasets accelerate gradio scikit-learn evaluate\n",
        "\n",
        "# Import libraries\n",
        "import torch\n",
        "import numpy as np\n",
        "import os\n",
        "from datasets import load_dataset\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForSequenceClassification,\n",
        "    TrainingArguments,\n",
        "    Trainer,\n",
        "    DataCollatorWithPadding\n",
        ")\n",
        "import evaluate\n",
        "import gradio as gr\n",
        "\n",
        "# Disable Weights & Biases logging (optional, prevents unnecessary logs)\n",
        "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
        "\n",
        "# Check if GPU is available, otherwise fallback to CPU\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Load the AG News dataset (train and test splits)\n",
        "raw_ds = load_dataset(\"ag_news\")\n",
        "\n",
        "# Split training set into train (90%) and validation (10%)\n",
        "splits = raw_ds[\"train\"].train_test_split(test_size=0.1, seed=42)\n",
        "train_ds = splits[\"train\"]\n",
        "val_ds = splits[\"test\"]\n",
        "test_ds = raw_ds[\"test\"]\n",
        "\n",
        "# Load tokenizer for BERT (converts text → tokens)\n",
        "model_name = \"bert-base-uncased\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Function to tokenize text data\n",
        "def tokenize(batch):\n",
        "    return tokenizer(batch[\"text\"], truncation=True)\n",
        "\n",
        "# Apply tokenization to train/val/test datasets\n",
        "train_tok = train_ds.map(tokenize, batched=True, remove_columns=[\"text\"])\n",
        "val_tok = val_ds.map(tokenize, batched=True, remove_columns=[\"text\"])\n",
        "test_tok = test_ds.map(tokenize, batched=True, remove_columns=[\"text\"])\n",
        "\n",
        "# Define label mapping (for readability of predictions)\n",
        "id2label = {0: \"World\", 1: \"Sports\", 2: \"Business\", 3: \"Sci/Tech\"}\n",
        "label2id = {v: k for k, v in id2label.items()}\n",
        "\n",
        "# Load pretrained BERT model for classification\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    model_name,\n",
        "    num_labels=4,        # 4 categories in AG News dataset\n",
        "    id2label=id2label,   # Map ID  label\n",
        "    label2id=label2id    # Map label  ID\n",
        ")\n",
        "\n",
        "# Load metrics (accuracy and F1-score)\n",
        "acc_metric = evaluate.load(\"accuracy\")\n",
        "f1_metric = evaluate.load(\"f1\")\n",
        "\n",
        "# Function to compute metrics during training/evaluation\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred                 # Predictions and true labels\n",
        "    preds = np.argmax(logits, axis=-1)         # Convert logits predicted class\n",
        "    return {\n",
        "        \"accuracy\": acc_metric.compute(predictions=preds, references=labels)[\"accuracy\"],\n",
        "        \"f1\": f1_metric.compute(predictions=preds, references=labels, average=\"weighted\")[\"f1\"]\n",
        "    }\n",
        "\n",
        "# Data collator: automatically pads text to same length in each batch\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
        "\n",
        "# Define training arguments\n",
        "args = TrainingArguments(\n",
        "    output_dir=\"bert-agnews\",\n",
        "    eval_strategy=\"epoch\",       # use eval_strategy for older versions\n",
        "    save_strategy=\"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=32,\n",
        "    num_train_epochs=3,\n",
        "    weight_decay=0.01,\n",
        "    logging_steps=500,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"accuracy\",\n",
        "    seed=42,\n",
        "    fp16=torch.cuda.is_available(),\n",
        "    report_to=[]\n",
        ")\n",
        "\n",
        "\n",
        "# Create Hugging Face Trainer object\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=args,\n",
        "    train_dataset=train_tok,\n",
        "    eval_dataset=val_tok,\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "print(\"Starting training\")\n",
        "trainer.train()\n",
        "print(\"Training complete\")\n",
        "\n",
        "# Evaluate model on validation set\n",
        "val_metrics = trainer.evaluate()\n",
        "print(\"\\nValidation Results:\")\n",
        "print(f\"Accuracy: {val_metrics['eval_accuracy']:.4f}\")\n",
        "print(f\"F1-Score: {val_metrics['eval_f1']:.4f}\")\n",
        "\n",
        "# Evaluate model on test set\n",
        "test_metrics = trainer.evaluate(test_tok)\n",
        "print(\"\\nTest Results:\")\n",
        "print(f\"Accuracy: {test_metrics['eval_accuracy']:.4f}\")\n",
        "print(f\"F1-Score: {test_metrics['eval_f1']:.4f}\")\n",
        "\n",
        "# Save trained model and tokenizer to local directory\n",
        "model.save_pretrained(\"./bert-news-classifier\")\n",
        "tokenizer.save_pretrained(\"./bert-news-classifier\")\n",
        "print(\"Model saved\")\n",
        "\n",
        "# Load trained model into a text classification pipeline\n",
        "from transformers import pipeline\n",
        "\n",
        "classifier = pipeline(\n",
        "    \"text-classification\",\n",
        "    model=\"./bert-news-classifier\",\n",
        "    tokenizer=\"./bert-news-classifier\",\n",
        "    device=0 if torch.cuda.is_available() else -1  # Run on GPU if available\n",
        ")\n",
        "\n",
        "# Function to classify a news headline\n",
        "def classify_news(text):\n",
        "    if not text.strip():   # Handle empty input\n",
        "        return \"Enter a news headline\"\n",
        "    result = classifier(text)                # Run prediction\n",
        "    confidence = result[0]['score']          # Confidence score\n",
        "    category = result[0]['label']            # Predicted category\n",
        "    return f\"Category: {category}\\nConfidence: {confidence:.2%}\"\n",
        "\n",
        "# Create Gradio app for interactive testing\n",
        "demo = gr.Interface(\n",
        "    fn=classify_news,\n",
        "    inputs=gr.Textbox(label=\"News Headline\", placeholder=\"Enter news headline\"),\n",
        "    outputs=gr.Textbox(label=\"Classification Result\"),\n",
        "    title=\"News Topic Classifier\",\n",
        "    examples = [\n",
        "    \"Microsoft announces new Windows update with security fixes\",\n",
        "    \"Pakistan wins T20 cricket match against India\",\n",
        "    \"SpaceX successfully lands reusable rocket\",\n",
        "    \"Pakistan faces Flash Floods in August\"\n",
        "]\n",
        ")\n",
        "# Launch demo with public sharing\n",
        "demo.launch(share=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "1244d8a71abb4052b5de2cc873174f65",
            "162d75c6b6974355977e784395ee9ce1",
            "914a58dd43a0436180603de5afb40460",
            "7ffafcca340c4d37bc52d16e6c1221e8",
            "c0e3eca472e84dfbb704103eedfa893f",
            "7259ebc70719455596705af411eeb111",
            "ae134e394be34aedac347f254339a19a",
            "c56a9e6087784e319ac196aea52c0b3f",
            "b4bcdc52f07940459d382b28e106f856",
            "0747bfbe2550404398d0e6e219c8d3ff",
            "a113b38b9389494796fc9cccea68cccb"
          ]
        },
        "id": "fqF3VLU915fm",
        "outputId": "6729ae8b-bd3f-4d52-ef36-ee8b7fa753e8"
      },
      "execution_count": 6,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mBuilding wheel for tokenizers \u001b[0m\u001b[1;32m(\u001b[0m\u001b[32mpyproject.toml\u001b[0m\u001b[1;32m)\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Building wheel for tokenizers (pyproject.toml) ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[31m  ERROR: Failed building wheel for tokenizers\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: ERROR: Failed to build installable wheels for some pyproject.toml based projects (tokenizers)\u001b[0m\u001b[31m\n",
            "\u001b[0mUsing device: cuda\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1244d8a71abb4052b5de2cc873174f65",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/12000 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/tmp/ipython-input-2178877029.py:97: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting training...\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='11718' max='20250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [11718/20250 21:08 < 15:23, 9.23 it/s, Epoch 1.74/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.199000</td>\n",
              "      <td>0.189247</td>\n",
              "      <td>0.941917</td>\n",
              "      <td>0.941850</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='20250' max='20250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [20250/20250 37:15, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.199000</td>\n",
              "      <td>0.189247</td>\n",
              "      <td>0.941917</td>\n",
              "      <td>0.941850</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.132300</td>\n",
              "      <td>0.183656</td>\n",
              "      <td>0.947167</td>\n",
              "      <td>0.947229</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.087900</td>\n",
              "      <td>0.223757</td>\n",
              "      <td>0.948500</td>\n",
              "      <td>0.948521</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training complete\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='613' max='375' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [375/375 00:32]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Validation Results:\n",
            "Accuracy: 0.9485\n",
            "F1-Score: 0.9485\n",
            "\n",
            "Test Results:\n",
            "Accuracy: 0.9462\n",
            "F1-Score: 0.9462\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://c3df89912ba2ff3253.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://c3df89912ba2ff3253.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    }
  ]
}