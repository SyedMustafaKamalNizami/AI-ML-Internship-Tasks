{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Task 4:\n",
        "# News Topic Classifier\n",
        "# Objective\n",
        "\n",
        "The objective of this task was to build a text classification system that categorizes news headlines into one of four categories (World, Sports, Business, Sci/Tech). This was achieved by fine-tuning a pretrained BERT model (bert-base-uncased) on the AG News dataset, allowing the model to learn context-specific patterns in news language for accurate classification.\n",
        "\n",
        "# Introduction\n",
        "\n",
        "This task involved applying transfer learning with the BERT model, a widely used transformer-based architecture for natural language processing. The AG News dataset, containing 120,000 training and 7,600 testing samples across four balanced categories, was used. The main goal was to demonstrate how a large pretrained model can be fine-tuned for a specific task without training from scratch. The process included tokenizing the text using the BERT tokenizer, preparing the dataset for training, fine-tuning the classification head, and finally deploying the model for real-time interaction using Gradio.\n",
        "\n",
        "# Overview\n",
        "\n",
        "The workflow began with loading the AG News dataset from Hugging Face Datasets and splitting the training set into training and validation subsets. The bert-base-uncased tokenizer converted each news headline into token IDs and attention masks suitable for BERT input. The model was fine-tuned using Hugging Face’s Trainer API.\n",
        "\n",
        "Evaluation was performed using accuracy and F1-score (weighted) to measure classification performance across all categories. The fine-tuned model and tokenizer were saved locally, and a Hugging Face pipeline was created for easy inference.\n",
        "\n",
        "For deployment, a Gradio interface was implemented, allowing users to input custom headlines and instantly view the predicted category with scores.\n",
        "\n",
        "# Summary\n",
        "\n",
        "This task successfully delivered a fine-tuned BERT-based text classifier capable of categorizing news headlines into predefined topics with strong accuracy and F1 performance. It demonstrated key skills in natural language processing, including tokenization, transformer fine-tuning, and evaluation. Furthermore, lightweight deployment through Gradio showcased how machine learning models can be made interactive and user-friendly."
      ],
      "metadata": {
        "id": "mY4PfpFIxTKC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required packages\n",
        "!pip install -q torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
        "!pip install -q transformers==4.21.0 datasets accelerate gradio scikit-learn evaluate\n",
        "\n",
        "# Import libraries\n",
        "import torch\n",
        "import numpy as np\n",
        "import os\n",
        "from datasets import load_dataset\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForSequenceClassification,\n",
        "    TrainingArguments,\n",
        "    Trainer,\n",
        "    DataCollatorWithPadding\n",
        ")\n",
        "import evaluate\n",
        "import gradio as gr\n",
        "\n",
        "# Disable Weights & Biases logging (optional, prevents unnecessary logs)\n",
        "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
        "\n",
        "# Check if GPU is available, otherwise fallback to CPU\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Load the AG News dataset (train and test splits)\n",
        "raw_ds = load_dataset(\"ag_news\")\n",
        "\n",
        "# Split training set into train (90%) and validation (10%)\n",
        "splits = raw_ds[\"train\"].train_test_split(test_size=0.1, seed=42)\n",
        "train_ds = splits[\"train\"]\n",
        "val_ds = splits[\"test\"]\n",
        "test_ds = raw_ds[\"test\"]\n",
        "\n",
        "# Load tokenizer for BERT (converts text → tokens)\n",
        "model_name = \"bert-base-uncased\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Function to tokenize text data\n",
        "def tokenize(batch):\n",
        "    return tokenizer(batch[\"text\"], truncation=True)\n",
        "\n",
        "# Apply tokenization to train/val/test datasets\n",
        "train_tok = train_ds.map(tokenize, batched=True, remove_columns=[\"text\"])\n",
        "val_tok = val_ds.map(tokenize, batched=True, remove_columns=[\"text\"])\n",
        "test_tok = test_ds.map(tokenize, batched=True, remove_columns=[\"text\"])\n",
        "\n",
        "# Define label mapping (for readability of predictions)\n",
        "id2label = {0: \"World\", 1: \"Sports\", 2: \"Business\", 3: \"Sci/Tech\"}\n",
        "label2id = {v: k for k, v in id2label.items()}\n",
        "\n",
        "# Load pretrained BERT model for classification\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    model_name,\n",
        "    num_labels=4,        # 4 categories in AG News dataset\n",
        "    id2label=id2label,   # Map ID  label\n",
        "    label2id=label2id    # Map label  ID\n",
        ")\n",
        "\n",
        "# Load metrics (accuracy and F1-score)\n",
        "acc_metric = evaluate.load(\"accuracy\")\n",
        "f1_metric = evaluate.load(\"f1\")\n",
        "\n",
        "# Function to compute metrics during training/evaluation\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred                 # Predictions and true labels\n",
        "    preds = np.argmax(logits, axis=-1)         # Convert logits predicted class\n",
        "    return {\n",
        "        \"accuracy\": acc_metric.compute(predictions=preds, references=labels)[\"accuracy\"],\n",
        "        \"f1\": f1_metric.compute(predictions=preds, references=labels, average=\"weighted\")[\"f1\"]\n",
        "    }\n",
        "\n",
        "# Data collator: automatically pads text to same length in each batch\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
        "\n",
        "# Define training arguments\n",
        "args = TrainingArguments(\n",
        "    output_dir=\"bert-agnews\",\n",
        "    eval_strategy=\"epoch\",       # use eval_strategy for older versions\n",
        "    save_strategy=\"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=32,\n",
        "    num_train_epochs=3,\n",
        "    weight_decay=0.01,\n",
        "    logging_steps=500,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"accuracy\",\n",
        "    seed=42,\n",
        "    fp16=torch.cuda.is_available(),\n",
        "    report_to=[]\n",
        ")\n",
        "\n",
        "\n",
        "# Create Hugging Face Trainer object\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=args,\n",
        "    train_dataset=train_tok,\n",
        "    eval_dataset=val_tok,\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "print(\"Starting training\")\n",
        "trainer.train()\n",
        "print(\"Training complete\")\n",
        "\n",
        "# Evaluate model on validation set\n",
        "val_metrics = trainer.evaluate()\n",
        "print(\"\\nValidation Results:\")\n",
        "print(f\"Accuracy: {val_metrics['eval_accuracy']:.4f}\")\n",
        "print(f\"F1-Score: {val_metrics['eval_f1']:.4f}\")\n",
        "\n",
        "# Evaluate model on test set\n",
        "test_metrics = trainer.evaluate(test_tok)\n",
        "print(\"\\nTest Results:\")\n",
        "print(f\"Accuracy: {test_metrics['eval_accuracy']:.4f}\")\n",
        "print(f\"F1-Score: {test_metrics['eval_f1']:.4f}\")\n",
        "\n",
        "# Save trained model and tokenizer to local directory\n",
        "model.save_pretrained(\"./bert-news-classifier\")\n",
        "tokenizer.save_pretrained(\"./bert-news-classifier\")\n",
        "print(\"Model saved\")\n",
        "\n",
        "# Load trained model into a text classification pipeline\n",
        "from transformers import pipeline\n",
        "\n",
        "classifier = pipeline(\n",
        "    \"text-classification\",\n",
        "    model=\"./bert-news-classifier\",\n",
        "    tokenizer=\"./bert-news-classifier\",\n",
        "    device=0 if torch.cuda.is_available() else -1  # Run on GPU if available\n",
        ")\n",
        "\n",
        "# Function to classify a news headline\n",
        "def classify_news(text):\n",
        "    if not text.strip():   # Handle empty input\n",
        "        return \"Enter a news headline\"\n",
        "    result = classifier(text)                # Run prediction\n",
        "    confidence = result[0]['score']          # Confidence score\n",
        "    category = result[0]['label']            # Predicted category\n",
        "    return f\"Category: {category}\\nConfidence: {confidence:.2%}\"\n",
        "\n",
        "# Create Gradio app for interactive testing\n",
        "demo = gr.Interface(\n",
        "    fn=classify_news,\n",
        "    inputs=gr.Textbox(label=\"News Headline\", placeholder=\"Enter news headline\"),\n",
        "    outputs=gr.Textbox(label=\"Classification Result\"),\n",
        "    title=\"News Topic Classifier\",\n",
        "    examples = [\n",
        "    \"Microsoft announces new Windows update with security fixes\",\n",
        "    \"Pakistan wins T20 cricket match against India\",\n",
        "    \"SpaceX successfully lands reusable rocket\",\n",
        "    \"Pakistan faces Flash Floods in August\"\n",
        "]\n",
        ")\n",
        "# Launch demo with public sharing\n",
        "demo.launch(share=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 610
        },
        "id": "fqF3VLU915fm",
        "outputId": "075e1844-5ff5-44ed-8fec-e64d0ebe434d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mBuilding wheel for tokenizers \u001b[0m\u001b[1;32m(\u001b[0m\u001b[32mpyproject.toml\u001b[0m\u001b[1;32m)\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Building wheel for tokenizers (pyproject.toml) ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[31m  ERROR: Failed building wheel for tokenizers\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: ERROR: Failed to build installable wheels for some pyproject.toml based projects (tokenizers)\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        },
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'evaluate'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1483466693.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mDataCollatorWithPadding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m )\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgradio\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mgr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'evaluate'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    }
  ]
}