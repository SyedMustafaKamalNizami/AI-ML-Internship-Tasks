{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d17dd17-7800-4f20-9ee1-e29c65eb3e34",
   "metadata": {},
   "source": [
    "# Task 6\n",
    "\n",
    "#  Auto Tagging Support Tickets Using LLM \n",
    "\n",
    "# Objective\n",
    "\n",
    "The objective of this task was to build an intelligent system that can automatically classify customer support tickets into predefined categories using a Large Language Model (LLM). This reduces the need for manual tagging, improves efficiency in handling support requests, and demonstrates how LLMs can be applied to practical customer service tasks.\n",
    "\n",
    "# Introduction\n",
    "\n",
    "This task involved working with a free-text support ticket dataset that included customer queries related to issues such as billing, login problems, technical errors, account management, and general inquiries. The challenge was to design an approach that leverages the natural language understanding capabilities of LLMs to assign meaningful tags without requiring extensive manual feature engineering. The implementation made use of OpenRouterâ€™s API to connect with the GPT-based model and classify tickets directly based on prompts. Both zero-shot and few-shot approaches were tested: the zero-shot approach provided predictions without prior examples, while the few-shot approach included some labeled examples in the prompt to guide the model toward more accurate classification.\n",
    "\n",
    "# Overview\n",
    "\n",
    "The process began by defining the five target categories for classification: Billing Issue, Login Problem, Technical Error, Account Management, and General Inquiry. For zero-shot classification, each support ticket was directly passed to the LLM along with instructions to choose the top three categories. For the few-shot classification, several examples of tickets paired with their correct categories were added to the prompt, helping the model learn from context before classifying new tickets. The outputs of both approaches included ranked categories with confidence-like scores, which were then simplified to take the top category as the predicted label. These predictions were compared against the true labels to measure performance. To evaluate results, accuracy and weighted F1 scores were calculated for both approaches. The zero-shot model achieved an accuracy of 0.80 with an F1 score of 0.73, while the few-shot model achieved an accuracy of 1 with a F1 score of 1, indicating improved balance between precision and recall. Since the dataset used was relatively small and custom, the performance difference between the two approaches was limited, but with a larger and more diverse dataset, the improvements of few-shot learning would likely be more significant and clearly visible in the results.\n",
    "\n",
    "# Evaluation\n",
    "\n",
    "The evaluation demonstrated that LLMs are highly effective for text classification tasks such as ticket tagging, even with little to no training. Zero-shot performance showed strong predictive power without prior examples, while the few-shot approach provided further improvement by incorporating contextual guidance. The results highlighted the flexibility of LLMs for multi-class prediction and ranking, as the model was able to output not only the top category but also the next most relevant categories with associated scores.\n",
    "\n",
    "# Summary\n",
    "\n",
    "This task successfully demonstrated how Large Language Models can be applied for auto-tagging support tickets, offering a scalable and efficient solution for customer support systems. By comparing zero-shot and few-shot learning approaches, it was shown that LLMs can adapt flexibly to classification tasks and provide accurate predictions even with minimal setup. The system built in this task is production-ready in concept, as it leverages API-based integration with an LLM and produces reusable outputs in a structured format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e57baebb-0f2c-4dfd-872d-851d2abb14dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Zero-Shot Classification\n",
      "\n",
      "Ticket: I was charged twice for my subscription this month.\n",
      "  Predictions: Billing Issue (0.9), Account Management (0.7), General Inquiry (0.3)\n",
      "\n",
      "Ticket: I can't log into my account even after resetting my password.\n",
      "  Predictions: Login Problem (90), Technical Error (60), Account Management (30)\n",
      "\n",
      "Ticket: The app crashes every time I upload a file.\n",
      "  Predictions: Technical Error (95), Account Management (5), General Inquiry (0)\n",
      "\n",
      "Ticket: How do I update my email address on the account?\n",
      "  Predictions: Account Management (0.8), General Inquiry (0.5), Login Problem (0.3).\n",
      "\n",
      "Ticket: I just want to know when my trial will expire.\n",
      "  Predictions: Account Management (0.9), General Inquiry (0.8), Billing Issue (0.2)\n",
      "\n",
      "Few-Shot Classification\n",
      "\n",
      "Ticket: I was charged twice for my subscription this month.\n",
      "  Predictions: Billing Issue (1), Account Management (0), General Inquiry (0)\n",
      "\n",
      "Ticket: I can't log into my account even after resetting my password.\n",
      "  Predictions: Login Problem (3), Account Management (1), Technical Error (1)\n",
      "\n",
      "Ticket: The app crashes every time I upload a file.\n",
      "  Predictions: Technical Error (3), Account Management (1), General Inquiry (1)\n",
      "\n",
      "Ticket: How do I update my email address on the account?\n",
      "  Predictions: Account Management (1), General Inquiry (0.5), Technical Error (0)\n",
      "\n",
      "Ticket: I just want to know when my trial will expire.\n",
      "  Predictions: General Inquiry (1.0), Billing Issue (0.5), Account Management (0.3)\n",
      "\n",
      "Performance Comparison\n",
      "Zero-Shot Accuracy: 0.8\n",
      "Zero-Shot F1 Score: 0.7333333333333333\n",
      "Few-Shot Accuracy: 1.0\n",
      "Few-Shot F1 Score: 1.0\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "\n",
    "# Setup OpenRouter client\n",
    "client = OpenAI(\n",
    "    base_url=\"https://openrouter.ai/api/v1\",\n",
    "    api_key=\"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\",\n",
    ")\n",
    "\n",
    "# Categories & Dataset (tuples: (ticket, label))\n",
    "categories = [\"Billing Issue\", \"Login Problem\", \"Technical Error\", \"Account Management\", \"General Inquiry\"]\n",
    "\n",
    "dataset = [\n",
    "    (\"I was charged twice for my subscription this month.\", \"Billing Issue\"),\n",
    "    (\"I can't log into my account even after resetting my password.\", \"Login Problem\"),\n",
    "    (\"The app crashes every time I upload a file.\", \"Technical Error\"),\n",
    "    (\"How do I update my email address on the account?\", \"Account Management\"),\n",
    "    (\"I just want to know when my trial will expire.\", \"General Inquiry\"),\n",
    "]\n",
    "\n",
    "# Helper: Ask LLM\n",
    "def classify_ticket(ticket, examples=None):\n",
    "    prompt = \"You are an AI assistant that classifies support tickets.\\n\"\n",
    "    if examples:\n",
    "        prompt += \"Here are some examples:\\n\"\n",
    "        for ex_text, ex_label in examples:\n",
    "            prompt += f\"Ticket: {ex_text}\\nCategory: {ex_label}\\n\"\n",
    "    prompt += f\"\\nNow classify this ticket:\\nTicket: {ticket}\\n\"\n",
    "    prompt += f\"Choose the best 3 categories from: {', '.join(categories)}.\\n\"\n",
    "    prompt += \"Return the answer as: Category1 (score), Category2 (score), Category3 (score).\"\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"openai/gpt-3.5-turbo\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "    )\n",
    "    return response.choices[0].message.content.strip()\n",
    "\n",
    "# Zero-Shot Classification\n",
    "print(\"\\nZero-Shot Classification\")\n",
    "zero_shot_preds = []\n",
    "true_labels = []\n",
    "\n",
    "for ticket, label in dataset:\n",
    "    result = classify_ticket(ticket)\n",
    "    print(f\"\\nTicket: {ticket}\\n  Predictions: {result}\")\n",
    "    top_prediction = result.split(\",\")[0].split(\"(\")[0].strip()\n",
    "    zero_shot_preds.append(top_prediction)\n",
    "    true_labels.append(label)\n",
    "\n",
    "# Few-Shot Classification\n",
    "few_shot_examples = [\n",
    "    (\"Payment failed but money was deducted\", \"Billing Issue\"),\n",
    "    (\"Can't log in even after resetting password\", \"Login Problem\"),\n",
    "    (\"App crashes when saving files\", \"Technical Error\"),\n",
    "    (\"Need to update profile information\", \"Account Management\"),\n",
    "    (\"What are your support hours\", \"General Inquiry\")\n",
    "]\n",
    "\n",
    "print(\"\\nFew-Shot Classification\")\n",
    "few_shot_preds = []\n",
    "\n",
    "for ticket, label in dataset:\n",
    "    result = classify_ticket(ticket, examples=few_shot_examples)\n",
    "    print(f\"\\nTicket: {ticket}\\n  Predictions: {result}\")\n",
    "    top_prediction = result.split(\",\")[0].split(\"(\")[0].strip()\n",
    "    few_shot_preds.append(top_prediction)\n",
    "# Performance Comparison\n",
    "print(\"\\nPerformance Comparison\")\n",
    "print(\"Zero-Shot Accuracy:\", accuracy_score(true_labels, zero_shot_preds))\n",
    "print(\"Zero-Shot F1 Score:\", f1_score(true_labels, zero_shot_preds, average=\"weighted\"))\n",
    "print(\"Few-Shot Accuracy:\", accuracy_score(true_labels, few_shot_preds))\n",
    "print(\"Few-Shot F1 Score:\", f1_score(true_labels, few_shot_preds, average=\"weighted\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0fa6729-100c-4e71-9c01-f54b3b1ac536",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
